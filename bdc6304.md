# Review of Robust Modeling and Optimization

## What we study - modeling and optimization under uncertainty
For Optimization, we need to decide decision variables, constraints and objective functions. 
When involving uncertainty, first, we use random variables to describe uncertainty. Then we need to find a way to incorporate uncertainty into
decision variables, constraints and objective functions. The decision variables could be a function of random variables and the random variables
could also be affected by decisions. For constraints, we could require some constraints with random variables holds with probability one, or 
chance constraints, or risk constraints. For objectives, it could be the expectation, or risk, or worst-case objective in some sense. 

- Endogeneous uncertainty vs. exogeneous uncertainty
- Nonanticipativity for both decision variables

- constraints: robust constraints; chance constraints; risk constraints;

- objectives: robust; expected; risk; 

## Methodology 
### stochastic programming (SP)
- we are talking in linear framework. 
- Time periods: SP is usually one stage or two stage, can be multi-stage. By stage we mean we can make decisions sequentially as uncertainty revealed in different stages. 
- decision variables are usually continuous; typically polyhedral. In general, the constraints can involve both decisions and uncertainty. So the feasible region decision in the next stage can depends on the uncertainty revealed in current stage. Objective is expectation so it has linearity. Multistage can be depcomposed to several two-stage problems. So we focus on two-stage SP. The goal is to detemine first stage decision, some assumptions are needed to gurantee the feasibility of second stage. 
- For uncertainty, in general the uncertainty can be both exogeneous and endogeneous, but endogeneous one means the decision-dependent uncertainty. And the uncertainty should be random variables with specific probability distributions. 

- For solution approach, for exogeneous uncertainty, we can sample from the distribution using Monte Carlo approach to get empirical approximation of expectation and solve the deterministic counterpart, this is sample average approximation (SAA). Another way is stochastic approximation (SA), just like solve deterministic optimizaiton problem using first order methods, but using sampling to get gradient approximation. SAA is usually combined with decompositioin algorithm like Benders decompostion to speed up compuation. We can also use other ways to approximate the expected recouse function, for example, construct certain tractable upper bounds via nonlinear programming or conic programming by leveraging problem or uncertainty structure like independence. 

- pros and cons: natural extension of deterministic problem; not too conservative since it is risk netural. usually intractable for large problem with many random variables and high-dim decisions. 


### robust optimization (RO)
we talk about one stage RO first. 
Robust means absolutely safe. In this case, the uncertainty is described with a set. We need to ensure the constraints are always feasible in any scenario and we are guaranteed to have the objetive. More specifically, RO replace the expectation in SP with worst-case scenario in the objective and make sure the decision is always feasible. Then we get infinite constraints, by using duality, we can get tractable form. The reason is worst-case maintains convexity and only consider one scenario one time.    
### distributionally robust optimization (DRO)

### risk approach

### satisficing approach

### dynamic programming

## Comparison: 
### which approach shall we adopt? 

## 

