---
layout: page
permalink: /personal/
---

[homepage](https://ascechen.github.io/) | [homepage](https://ascechen.github.io/) | [homepage](https://ascechen.github.io/)


### Personal Stuff

<div class="fig figleft fighighlight">
 Â <img src="/picture/me.jpg">
  <div class="figcaption">
       Photo 
  which tells us the direction of the steepest decrease in the loss function. Small steps are likely to lead to consistent but slow progress. Large steps can lead to better progress but are more risky. Note that eventually, for a large step size we will overshoot and make the loss worse. The step size (or as we will later call it - the <b>learning rate</b>) will become one of the most important hyperparameters that we will have to carefully tune.
  </div>
  <div style="clear:both;"></div>
</div>

lasfdlasjfda


<div class="fig figcenter fighighlight">
  <img src="/picture/me.jpg">
  <img src="/picture/me.jpg">
  <img src="/picture/me.jpg">
  <div class="figcaption">
    Loss function landscape for the Multiclass SVM (without regularization) for one single example (left,middle) and for a hundred examples (right) in CIFAR-10. Left: one-dimensional loss by only varying <b>a</b>. Middle, Right: two-dimensional loss slice, Blue = low loss, Red = high loss. Notice the piecewise-linear structure of the loss function. The losses for multiple examples are combined with average, so the bowl shape on the right is the average of many piece-wise linear bowls (such as the one in the middle).
  </div>
</div>

